!pip install langchain transformers sentence-transformers faiss-cpu
!pip install -U langchain langchain-community


import os

# 이건 구글 colab 에 연동할때만 필요한 코드에요
# ▶ Colab 드라이브 마운트 및 문서 불러오기
from google.colab import drive
drive.mount('/content/drive')
# 이건 구글 colab 에 연동할때만 필요한 코드에요 END


# 드라이브 상의 폴더 경로 설정
folder_path = "/content/drive/MyDrive/dataset/text"

# 폴더 내 모든 .txt 파일 경로 리스트로 가져오기
file_list = [os.path.join(folder_path, fname) for fname in os.listdir(folder_path) if fname.endswith(".txt")]

# 모든 파일 내용 읽어서 리스트에 저장
texts = []
for file_path in file_list:
    with open(file_path, 'r', encoding='utf-8') as f:
        texts.append(f.read())
print(texts)


# ▶ 문서 청크로 나누기
from langchain.text_splitter import CharacterTextSplitter
splitter = CharacterTextSplitter(
    separator="\n",
    chunk_size=500,
    chunk_overlap=50,
    length_function=len
)

# 여러 개의 문서를 한번에 청크로 나누기
documents = splitter.create_documents(texts)


# ▶ 임베딩 및 FAISS 구축
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS

embedding_model = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)
vector_db = FAISS.from_documents(documents, embedding_model)
save_path = "/content/drive/MyDrive/embedding/rag"
vector_db.save_local(save_path)




# 사용 예제
# ▶ FAISS 재로드 및 검색 테스트    save_path = "/content/drive/MyDrive/embedding/rag"
vector_db = FAISS.load_local(save_path, embedding_model, allow_dangerous_deserialization=True)
retriever = vector_db.as_retriever(search_kwargs={"k": 8})

# ▶ Gemini API 연결
import google.generativeai as genai
genai.configure(api_key="AIzaSyCj_KP3tWm9_3cgbjvQrZl5vv2M3_DBfZ0")

model = genai.GenerativeModel("gemini-2.5-flash")

# ▶ 사용자 정의 프롬프트 및 QA 체인 정의 (LangChain 없이 직접)
def gemini_rag_answer(query):
    docs = retriever.get_relevant_documents(query)
    context = "\n".join([doc.page_content for doc in docs])

    prompt = f"""
당신은 문서 기반 질문에 답하는 AI입니다.
다음 문서를 참고해서 질문에 답하십시오:

문서:
{context}

질문:
{query}

답변:
"""
    response = model.generate_content(prompt)
    return response.text

# ▶ 테스트
query = "뭘 파니"
answer = gemini_rag_answer(query)
print("📌 질문:", query)
print("🤖 Gemini 답변:", answer)
# 사용 예제 END
